{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7db14cab-03d5-479d-b56d-31a583ba7b7e",
   "metadata": {},
   "source": [
    "# QR Algorithm and an Application\n",
    "\n",
    "You have read about the QR alogorithm, a computational technique for accounting eigenvectors and eigenvalues. To implement the algorithm, we first need to write an algorithm for the QR decomposition. \n",
    "\n",
    "Exercise 6.8 describes the process of QR decomposition in some detail, but does not provide code. Let's code it.\n",
    "\n",
    "The process in Exercise 6.8 obviously lends itself to being iterative. We'll define three matrices: U, Q, and R. Q and R are obvious, U will store the vectors $\\vec{u}$ needed to build up the vectors $\\vec{q}$ and the matrix R.\n",
    "\n",
    "For each iteration, we first copy over the vector $\\vec{a_i}$ to $\\vec{u_i}$. Next we need the magnitude $|\\vec{u_i}|$, and since these are precisely the diagonal elements of R, we'll store the magnitude there. Now we can calculate $\\vec{q_i}$ trivially. Finally we need to calculate the off-diagonal elements of R, and if i > 0, we have more terms in $\\vec{u_i}$. We're going to be unnecessarily clever for $\\vec{u_i}$. Notice all the terms we need to calculate it are calculated elsewhere, so we'll re-use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697be931-7112-4e2a-9098-4d494a8e1ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=3)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "def QR(A):\n",
    "    N = A.shape[0]\n",
    "    U = np.empty([N,N])\n",
    "    Q = np.empty([N,N])\n",
    "    # R is upper triangular so we won't populate half, it's convenient to begin with zeroes\n",
    "    R = np.zeros([N,N])\n",
    "\n",
    "    for i in range(N):\n",
    "        U[:,i] = A[:,i]\n",
    "        # remember i starts at 0, feel free to try a for loop for range(0) if you don't understand the magic\n",
    "        for j in range(i):\n",
    "            R[j,i] = np.dot(Q[:,j], A[:,i])\n",
    "            U[:,i] -= R[j,i] * Q[:,j]\n",
    "        R[i,i] = np.sqrt(np.dot(U[:,i], U[:,i]))\n",
    "        Q[:,i] = U[:,i] / R[i,i]\n",
    "    \n",
    "    return Q, R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff426d43-da49-4e11-ab0d-0a4f33db92d4",
   "metadata": {},
   "source": [
    "The second part of the QR algorithm is simply calling the QR function over and over until we hit a desired precision. We'll use the matrix given in Exercise 6.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff8bc9d-0ab8-4fcd-8078-388e4cfdf883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def QReigen(A, verbose=False):\n",
    "    epsilon = 1e-6\n",
    "    \n",
    "    N = A.shape[0]\n",
    "    \n",
    "    V = np.identity(N, float)\n",
    "    delta = 100.0\n",
    "    runs = 0\n",
    "    while runs < 1000:\n",
    "        runs += 1\n",
    "        Q, R = QR(A)\n",
    "\n",
    "        A = np.dot(R, Q)\n",
    "        V = np.dot(V, Q)\n",
    "    \n",
    "        # find max of the off-diagonal elements\n",
    "        Ac = np.copy(A)\n",
    "        for i in range(N):\n",
    "            Ac[i,i] = 0.0\n",
    "        # if delta < np.max(np.absolute(Ac)):\n",
    "        #     assert False, \"it's dead jim\"\n",
    "        delta = np.max(np.abs(Ac))\n",
    "        if verbose:\n",
    "            print(delta)\n",
    "        if delta < epsilon:\n",
    "            break\n",
    "\n",
    "    eigenvals = [A[i,i] for i in range(N)]\n",
    "    return eigenvals, V\n",
    "\n",
    "A = [[1, 4, 8, 4],\n",
    "     [4, 2, 3, 7],\n",
    "     [8, 3, 6, 9],\n",
    "     [4, 7, 9, 2]]\n",
    "\n",
    "A = np.array(A, float)\n",
    "\n",
    "eigenvals, V = QReigen(A, verbose=True)\n",
    "\n",
    "print(eigenvals)\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e77b8b0-e2c6-4b48-b19f-989a0aff56f3",
   "metadata": {},
   "source": [
    "## SVD (Singular Value Decomposition)\n",
    "\n",
    "The idea behind SVD is that any matrix $A$ can be expressed as the the product of a set of vectors. Given a matrix $A$ of size $ m \\times n$:\n",
    "\n",
    "$$\n",
    "A = U \\Sigma V^T\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $U$ is an $ m \\times m$ orthogonal matrix whose columns are the left singular vectors of A\n",
    "- $\\Sigma$ is a a diagonal $ m \\times n$ matrix containing the singular values of A in descending order\n",
    "- $V^T$ is the transpose of an $n \\times n$ orthogonal matrix where the columns are the right singular vectors of A.\n",
    "\n",
    "The singular values turn out to closely related to the eigenvalues of $A A^T$, and the vectors that make up U are *exactly* the eigenvectors of $A A^T$.\n",
    "\n",
    "The vectors that make up $V$ are the eigenvectors of $A^T A$.\n",
    "\n",
    "This is all we need to write down a function to compute SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909fb539-3ec5-4cc6-9ed5-ba5466fd4251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd(A):\n",
    "    A_t = np.transpose(A)\n",
    "    right_vals, right_vecs =  QReigen(np.matmul(A, A_t))\n",
    "    left_vals, left_vecs =  QReigen(np.matmul(A_t, A))\n",
    "\n",
    "    U = right_vecs\n",
    "    V_t = np.transpose(left_vecs)\n",
    "\n",
    "    if len(left_vals) > len(right_vals):\n",
    "        sigma = np.sqrt(np.array(right_vals))\n",
    "        for i in range(len(sigma)):\n",
    "            if np.abs(sigma[i]) < 1e-8 or np.isnan(sigma[i]):\n",
    "                sigma[i] = 0\n",
    "        V_t = V_t[:len(right_vals)]\n",
    "    else:\n",
    "        sigma = np.sqrt(np.array(left_vals))\n",
    "        for i in range(len(sigma)):\n",
    "            if np.abs(sigma[i]) < 1e-8 or np.isnan(sigma[i]):\n",
    "                sigma[i] = 0\n",
    "        U = U[:,:len(left_vals)]\n",
    "\n",
    "    return U, sigma, V_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05079c28-7b32-44e3-bf3e-c1abd4d87f12",
   "metadata": {},
   "source": [
    "Testing this function is trivial. If we can reconstruct the initial matrix, we've succeeded.\n",
    "\n",
    "Of course there is a numpy implementation of SVD. We can verify our answers are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe4e722-1ba2-413e-bcfa-85b7a0c1393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array([[3, 2, 2],\n",
    "                 [2, 3, -2]], float)\n",
    "U, sigma, V_t = svd(test)\n",
    "print(U)\n",
    "print(sigma)\n",
    "print(V_t)\n",
    "print(np.dot(U * sigma, V_t))\n",
    "\n",
    "U, sigma, V_t = np.linalg.svd(test, full_matrices=False)\n",
    "print(U)\n",
    "print(sigma)\n",
    "print(V_t)\n",
    "print(np.dot(U * sigma, V_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd67e21-c6bd-4c3b-9715-783f000965a6",
   "metadata": {},
   "source": [
    "There is little utility in decomposing a small matrix into it's component parts. But as matrices become more complex, the utility of extracting a smaller set of vectors that can accuratel express the entire matrix becomes clear. This is for example one way to compress 2D images!\n",
    "\n",
    "Note below our code doesn't do quite as well for this larger matrix. This is mostly a function of the author not having infinite time! Some careful handling of the ordering of vectors would probably improve the result.\n",
    "\n",
    "But of course the numpy implementation works great! So we can \"graduate\" to using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030ec3ff-4bba-4667-8ad1-74800d128efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array([[1, 1, 1, 0, 0],\n",
    "                 [3, 3, 3, 0, 0],\n",
    "                 [4, 4, 4, 0, 0],\n",
    "                 [5, 5, 5, 0, 0],\n",
    "                 [0, 2, 0, 4, 4],\n",
    "                 [0, 0, 0, 5, 5],\n",
    "                 [0, 1, 0, 2, 2]], float) \n",
    "\n",
    "U, sigma, V_t = svd(test)\n",
    "\n",
    "print(np.dot(U * sigma, V_t), \"\\n\\n\\n\")\n",
    "\n",
    "U, sigma, V_t = np.linalg.svd(test, full_matrices=False)\n",
    "\n",
    "print(np.dot(U * sigma, V_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e2f85d-2c5c-4474-a955-4de4ab9d8225",
   "metadata": {},
   "source": [
    "Now time for some dimensionality reduction. Looking at our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cf81fe-2aba-430a-a5cc-d2e768562864",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5143637d-166a-463b-a5af-6a32700fb684",
   "metadata": {},
   "source": [
    "Two of our singular values are 0. One of them is very small compared to the others. Can we accurately create the whole matrix from two vectors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffaf7df-7486-4091-af66-a8a09496bfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "U, sigma, V_t = np.linalg.svd(test, full_matrices=False)\n",
    "\n",
    "k = 2\n",
    "\n",
    "U = U[:,:k]\n",
    "V_t = V_t[:k]\n",
    "sigma = sigma[:k]\n",
    "\n",
    "print(np.dot(U * sigma, V_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb426b9-7759-4ae3-8e7f-2489e9a1a57e",
   "metadata": {},
   "source": [
    "# Application: PCA\n",
    "\n",
    "PCA (Principle Component Analysis) is a well known algorithm often lumped into the \"machine learning\" category, but as with many algorithms lumped into that category, there isn't a lot of learning going on; it is just a simple algorithm using eigenvector decomposition.\n",
    "\n",
    "The following exercises are shamelessly borrowed from [This notebook](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.09-Principal-Component-Analysis.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef9e034-7d47-47e8-9d46-12b9840b907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7cc77f-68df-496e-b972-00af1d56c027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digits(data):\n",
    "    fig, axes = plt.subplots(4, 10, figsize=(10, 4),\n",
    "                             subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                             gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(data[i].reshape(8, 8),\n",
    "                  cmap='binary', interpolation='nearest',\n",
    "                  clim=(0, 16))\n",
    "plot_digits(digits.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94516131-5d18-4d78-af19-9d28dbda28b3",
   "metadata": {},
   "source": [
    "Now add some noise and plot noisy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d87ee8-7389-4775-a650-24033bdd0b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "noisy = rng.normal(digits.data, 4)\n",
    "plot_digits(noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85f5278-5a04-4646-b59b-dca793a61dcc",
   "metadata": {},
   "source": [
    "The sklearn PCA package has builtin functionality to determine a reasonable amount of dimensionality reduction.\n",
    "\n",
    "The code below computes the number of components required to account for 50% of the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e985d9-cfd2-468a-9e0e-8c7f10cf3f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(0.50).fit(noisy)\n",
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7bbd9a-d0d7-4ede-b1dc-a3bb8dce9bf3",
   "metadata": {},
   "source": [
    "Now we can reconstruct the original data from only those components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793e22b0-aa03-4e8f-aa0d-96dfba15c81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "components = pca.transform(noisy)\n",
    "filtered = pca.inverse_transform(components)\n",
    "plot_digits(filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2831dac1-2906-4537-b997-b5d071f2ec2c",
   "metadata": {},
   "source": [
    "A bit noisy. The more interesting example is\n",
    "\n",
    "## Eigenfaces\n",
    "\n",
    "The same principle used to reconstruct the numbers can be used to reconstruct any image.\n",
    "\n",
    "In the number example, there are initially 64 dimensions (64 pixels with a single number describing opacity in each pixel). 12 eigenvectors was sufficient to account for 50% of the variance in 64 pixels; a notably impressive result. What do we need to describe more complicated images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f387105e-82db-400a-bbf3-fc63c42b55c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "faces = fetch_lfw_people(min_faces_per_person=60)\n",
    "print(faces.target_names)\n",
    "print(faces.images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53f5df4-4132-4111-aa9c-03535253d0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 8, figsize=(9, 4),\n",
    "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(faces.data[i].reshape(62, 47), cmap='bone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d840f679-3ac2-4865-9e19-20b138ca5222",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(150, svd_solver='randomized', random_state=42)\n",
    "pca.fit(faces.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955bb505-0481-4739-91df-7ca09258bc89",
   "metadata": {},
   "source": [
    "There is now a set of 150 component eigenvectors which can in theory be used to re construct the faces. \n",
    "\n",
    "It is interesting to view these \"eigenfaces\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ec9644-bad1-4636-92a6-2fcd6bc351ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 8, figsize=(9, 4),\n",
    "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(pca.components_[i].reshape(62, 47), cmap='bone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e969ed87-6ba8-4b1a-9250-7c966abcc492",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7a7bd4-495a-4b2f-8de3-41274dd1ed04",
   "metadata": {},
   "source": [
    "The plot tells us the 150 components computed account for some 90% of the data, suggesting we can reconstruct the faces quite well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc0414d-5150-41b8-b511-cc48e332ecff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = pca.fit(faces.data)\n",
    "components = pca.transform(faces.data)\n",
    "projected = pca.inverse_transform(components)\n",
    "\n",
    "fig, ax = plt.subplots(2, 10, figsize=(10, 2.5),\n",
    "                       subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                       gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "for i in range(10):\n",
    "    ax[0, i].imshow(faces.data[i].reshape(62, 47), cmap='binary_r')\n",
    "    ax[1, i].imshow(projected[i].reshape(62, 47), cmap='binary_r')\n",
    "    \n",
    "ax[0, 0].set_ylabel('full-dim\\ninput')\n",
    "ax[1, 0].set_ylabel('150-dim\\nreconstruction');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6eaf3e-d273-49b3-9666-4d492b8f2b68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
