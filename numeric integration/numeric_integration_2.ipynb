{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5514a7ae-b460-4085-8508-c5db3a414156",
   "metadata": {},
   "source": [
    "# Numeric Integration 2\n",
    "\n",
    "### Uncertainty on The trapezoid rule\n",
    "\n",
    "Recall the integral we've been using for examples, $\\int_{0}^{2} ( x^4 - 2x + 1)dx$. Eq. 5.28 suggests we can estimate an uncertainty on our integral by integrating the function twice, one with $N$ steps and once with $2N$. Using $N=10$ and $N=20$ estimate the accuracy of your integral. How does it compare to the actual discrepancy with the known true value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2253f858-0f20-4870-bf70-54a3ef14c914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.506560000000001\n",
      "4.426660000000002\n",
      "0.026633333333333137\n"
     ]
    }
   ],
   "source": [
    "# code\n",
    "import numpy as np\n",
    "\n",
    "def f_1(x):\n",
    "    return x**4 - 2*x + 1\n",
    "\n",
    "def trapezoidSum(function, a, b, N_steps):\n",
    "    h = (b-a) / N_steps\n",
    "    total = 0.5*h * (function(a) + function(b))\n",
    "\n",
    "    for k in range(1,N_steps):\n",
    "        total += h * function(a + k*h)\n",
    "\n",
    "    return total\n",
    "\n",
    "print(trapezoidSum(f_1, 0, 2, 10))\n",
    "print(trapezoidSum(f_1, 0, 2, 20))\n",
    "\n",
    "print(np.abs((trapezoidSum(f_1, 0, 2, 10) - trapezoidSum(f_1, 0, 2, 20)) / 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b79ab8-fd59-4f3f-b421-a382a0d6b48a",
   "metadata": {},
   "source": [
    "### Adaptive Trapezoid Rule\n",
    "\n",
    "Sec 5.3 outlines a method for iteratively doubling the number of steps in a trapezoid rule until a desired precision is achieved. Write a function to implement this method for our test integral, $\\int_{0}^{2} ( x^4 - 2x + 1)dx$, until a desired precision is reached. Choose your own goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97c5b8db-41b5-415b-903c-7076121c0aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 steps, error: 0.026633333333333137\n",
      "20 steps, error: 0.006664583333333122\n",
      "40 steps, error: 0.0016665364583333304\n",
      "80 steps, error: 0.00041665852864565994\n",
      "160 steps, error: 0.0001041661580408378\n",
      "320 steps, error: 2.604163487873734e-05\n",
      "4.400104166564945\n"
     ]
    }
   ],
   "source": [
    "# code\n",
    "def AdaptiveTrapSum(function, a, b, N_steps = 10, tolerance = 0.0001, recursing = True, step_skip = 1, last_total = 0):\n",
    "    h = (b-a) / N_steps\n",
    "    if last_total == 0:\n",
    "        total = 0.5*h * (function(a) + function(b))\n",
    "    else:\n",
    "        total = last_total\n",
    "\n",
    "    for k in range(1, N_steps, step_skip):\n",
    "        total += h * function(a + k*h)\n",
    "\n",
    "    if recursing == True:\n",
    "        trap_error = np.abs(total - AdaptiveTrapSum(function, a, b, N_steps=2*N_steps, recursing=False)) / 3\n",
    "        print(f\"{N_steps} steps, error: {trap_error}\")\n",
    "        \n",
    "        if trap_error >= tolerance:\n",
    "            total = AdaptiveTrapSum(function, a, b, N_steps=2*N_steps, tolerance=tolerance, recursing=True, step_skip=2, last_total=total/2)\n",
    "\n",
    "    return total\n",
    "\n",
    "print(AdaptiveTrapSum(f_1, 0, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15b3013-99aa-46e0-969a-82873270872e",
   "metadata": {},
   "source": [
    "With your method established in principle, use the same function or write a new one to evaluate the integral $\\int_{0}^{1} \\sin^2 \\sqrt{100x} dx$ to a precision of $\\epsilon \\sim 10^{-6}$. Begin with a single slice and work your way up to two, four, eight, etc. At each step, print the number of slices and the error.\n",
    "\n",
    "The correct answer is around 0.45."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "271516c3-54d2-4078-84f2-c4370d3c5b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 steps, error: 0.05908414108660753\n",
      "2 steps, error: 0.06235031430561896\n",
      "4 steps, error: 0.036428467415027734\n",
      "8 steps, error: 0.009035306938832885\n",
      "16 steps, error: 0.00610376549757428\n",
      "32 steps, error: 0.0018327551426353301\n",
      "64 steps, error: 0.000478524385808754\n",
      "128 steps, error: 0.00012092069347964991\n",
      "256 steps, error: 3.0311066141097687e-05\n",
      "512 steps, error: 7.582826918632139e-06\n",
      "1024 steps, error: 1.8960230754871965e-06\n",
      "2048 steps, error: 4.7402554131936725e-07\n",
      "0.4558306362016466\n"
     ]
    }
   ],
   "source": [
    "# code\n",
    "def f_2(x):\n",
    "    return np.sin(np.sqrt(100 * x))**2\n",
    "\n",
    "print(AdaptiveTrapSum(f_2, 0, 1, N_steps=1, tolerance=1e-6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5df34fd-169b-469b-aa35-458da1e0499d",
   "metadata": {},
   "source": [
    "Repeat the previous exercise using the adaptive Simpson's Rule. You should find signficantly fewer steps are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "349e35a7-a2c9-4364-8579-4f83b21ecc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 steps, error: 0.003796024366896744\n",
      "20 steps, error: 0.0004731630961837263\n",
      "40 steps, error: 3.44740157342686e-05\n",
      "80 steps, error: 2.236766804456873e-06\n",
      "160 steps, error: 1.4110396072316195e-07\n",
      "0.45583027431256834\n"
     ]
    }
   ],
   "source": [
    "# code\n",
    "\n",
    "def AdaptiveSimpSum(function, a, b, N_steps = 10, tolerance = 0.0001, recursing = True, last_total = 0):\n",
    "    h = (b-a) / N_steps\n",
    "    total_T, total_I = 0, 0\n",
    "    if last_total == 0:\n",
    "        total_S = (1/3) * (function(a) + function(b))\n",
    "        for k in range(2, N_steps-1, 2):\n",
    "            total_S += (2/3) * function(a + k*h)\n",
    "    else:\n",
    "        total_S = last_total\n",
    "\n",
    "    for k in range(1, N_steps, 2):\n",
    "        total_T += (2/3) * function(a + k*h)\n",
    "\n",
    "    total_I = h * (total_S + 2*total_T)\n",
    "\n",
    "    if recursing == True:\n",
    "        simp_error = np.abs(total_I - AdaptiveSimpSum(function, a, b, N_steps=2*N_steps, recursing=False)) / 15\n",
    "        print(f\"{N_steps} steps, error: {simp_error}\")\n",
    "        \n",
    "        if simp_error >= tolerance:\n",
    "            total_I = AdaptiveSimpSum(function, a, b, N_steps=2*N_steps, tolerance=tolerance, recursing=True, last_total=(total_S + total_T))\n",
    "\n",
    "    return total_I\n",
    "\n",
    "print(AdaptiveSimpSum(f_2, 0, 1, tolerance=1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaaceba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
